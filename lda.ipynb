{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZdPi_CWMAqx",
        "outputId": "f025938b-0886-473c-b17a-7a72b99188d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nivalderramas/dev/horus/lda/venv/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
            "  from imp import reload\n"
          ]
        }
      ],
      "source": [
        "# Run in terminal or command prompt\n",
        "# python3 -m spacy download en\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import re, nltk, spacy, gensim\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from pprint import pprint\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "#collection data is being loaded from\n",
        "collection =  \"lda_info\"\n",
        "#documents data is being loaded from\n",
        "documents = [\n",
        "  \"_id\",\n",
        "  \"dc:description:eng\",\n",
        "  \"dc:title:eng\"\n",
        "]#read file\n",
        "f = open(\"avois_words.txt\", \"r\")\n",
        "#this is a list of words that are not relevant to the topic\n",
        "stopwords = f.read().splitlines()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pymongo import MongoClient\n",
        "\n",
        "#Function to convert dictionary into a sorted list with max_qty \n",
        "pipeline = [\n",
        "    {\"$project\": {\"dc:description:eng\":1, \"dc:title:eng\":1}},\n",
        "\n",
        "]\n",
        "\n",
        "def get_mongo_conn(host='localhost', port=27018):\n",
        "  \"\"\" \n",
        "  retorna la conexion a la base de datos mongo en caso\n",
        "  de ser posible\n",
        "  \"\"\"\n",
        "  username_db = \"mongo-root\"\n",
        "  password_db = \"horus.mongo.2020\"\n",
        "  try:\n",
        "    return MongoClient(host, port, username=username_db, password=password_db)\n",
        "  except Exception as e:\n",
        "    print(\"No se pudo establecer conexion con la base de datos mongo\")\n",
        "    print(e)\n",
        "    return None\n",
        "  \n",
        "client = get_mongo_conn()\n",
        "db = client['VT']\n",
        "\n",
        "def get_data():\n",
        "  data = []\n",
        "  cnt = 0\n",
        "  for document in db[collection].aggregate(pipeline):\n",
        "    new_doc = []\n",
        "    for(key, value) in document.items():\n",
        "      if(key in documents):\n",
        "        new_doc.append(key + \":\" + str(value))\n",
        "    data.append(new_doc)\n",
        "  return data\n",
        "data = get_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyIjEYU3M4-j",
        "outputId": "c7a931af-9e32-4faf-9fb2-7d70195e498e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['dc', 'title', 'eng', 'systematic', 'evaluation', 'of', 'jatropha', 'curcas', 'oil', 'obtention', 'by', 'mechanical', 'and', 'solvent', 'extraction', 'dc', 'description', 'eng', 'current', 'biodiesel', 'production', 'relies', 'mostly', 'on', 'edible', 'oils', 'soybean', 'palm', 'rapeseed', 'which', 'is', 'major', 'drawback', 'for', 'the', 'process', 'as', 'raw', 'materials', 'represent', 'the', 'major', 'part', 'of', 'the', 'final', 'costs', 'of', 'the', 'biofuel', 'this', 'also', 'brings', 'out', 'concerns', 'about', 'food', 'and', 'feed', 'security', 'in', 'the', 'last', 'years', 'jatropha', 'curca', 'oil', 'has', 'obtained', 'attention', 'as', 'an', 'alternative', 'oleochemical', 'feedstock', 'because', 'it', 'is', 'perennial', 'crop', 'able', 'to', 'produce', 'up', 'to', 'gallon', 'per', 'hectare', 'year', 'of', 'non', 'edible', 'oil', 'even', 'though', 'several', 'authors', 'have', 'reported', 'process', 'conditions', 'and', 'yields', 'on', 'variety', 'of', 'extraction', 'methods', 'for', 'jatropha', 'oil', 'few', 'of', 'them', 'present', 'details', 'on', 'the', 'overall', 'process', 'from', 'the', 'industrial', 'standpoint', 'and', 'also', 'most', 'of', 'them', 'do', 'not', 'assess', 'the', 'impact', 'of', 'the', 'extraction', 'process', 'on', 'the', 'oil', 'quality', 'and', 'its', 'technical', 'requirements', 'for', 'biodiesel', 'production', 'in', 'this', 'regard', 'this', 'work', 'describes', 'the', 'development', 'of', 'jatropha', 'oil', 'production', 'process', 'involving', 'mechanical', 'and', 'solvent', 'extraction', 'the', 'effect', 'of', 'mechanical', 'extraction', 'parameters', 'such', 'as', 'speed', 'of', 'the', 'screw', 'diameter', 'and', 'temperature', 'of', 'discharge', 'each', 'one', 'was', 'analyzed', 'on', 'oil', 'yield', 'and', 'saponification', 'index', 'as', 'quality', 'parameter', 'expeller', 'power', 'consumption', 'and', 'extraction', 'efficiency', 'were', 'studied', 'in', 'solvent', 'extraction', 'experiments', 'it', 'was', 'evaluated', 'the', 'effect', 'of', 'the', 'nature', 'of', 'solvent', 'by', 'using', 'hexano', 'methanol', 'and', 'ethanol', 'the', 'seed', 'solvent', 'mass', 'ratio', 'and', 'and', 'the', 'particle', 'size', 'and', 'mm', 'on', 'oil', 'yield', 'and', 'oil', 'properties', 'saponification', 'index', 'humidity', 'the', 'most', 'favorable', 'conditions', 'of', 'each', 'extraction', 'process', 'were', 'established', 'an', 'optimization', 'study', 'allowed', 'establishing', 'most', 'favorable', 'conditions', 'for', 'industrial', 'processing', 'involving', 'mechanical', 'extraction', 'of', 'the', 'seeds', 'and', 'solvent', 'extraction', 'of', 'the', 'pressed', 'cake', 'oil', 'obtained', 'with', 'this', 'process', 'was', 'characterized', 'and', 'used', 'for', 'biodiesel', 'production']]\n"
          ]
        }
      ],
      "source": [
        "#TOKENIZE WORDS\n",
        "def tokenize_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(tokenize_words(data))\n",
        "\n",
        "print(data_words[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n7jwMtqNFDT",
        "outputId": "5f2a82c3-aea7-433e-9ab8-860b8f097d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['evaluation oil obtention mechanical solvent extraction dc description current biodiesel production rely mostly edible oil soybean rapeseed major drawback process raw material represent major part final cost biofuel also bring concern food feed security last year curca oil obtain attention alternative oleochemical feedstock perennial crop able produce gallon hectare year edible oil even several author report process condition yield variety extraction method jatropha oil few present detail overall process industrial standpoint also most assess impact extraction process oil quality technical requirement biodiesel production regard work describe development jatropha oil production process involve mechanical solvent extraction effect mechanical extraction parameter such speed screw diameter temperature discharge one analyze oil yield saponification index quality parameter expeller power consumption extraction efficiency study solvent extraction experiment evaluate effect nature solvent use hexano methanol ethanol seed solvent mass ratio particle size mm oil yield oil property saponification index humidity most favorable condition extraction process establish optimization study allow establish most favorable condition industrial processing involve mechanical extraction seed solvent extraction press cake oil obtain process characterize use biodiesel production', 'scheduling algorithm wimax network dc description wireless access base ieee standard know wimax technology promise provide service next generation wireless system high transmission rate quality service qo standard use control access connection orient mac define qos scheme paper show scheduling algorithm such round robin rr defic round robin drr future implementation wimax network ieee']\n"
          ]
        }
      ],
      "source": [
        "#LEMMATIZATION\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
        "    return texts_out\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
        "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4IDQALm-QrRj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(742, 982)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nivalderramas/dev/horus/lda/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['activated', 'cytokine', 'diet', 'induced', 'line', 'lisis', 'perzonalized', 'realiz', 'spin', 'strategies'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Create document word matrix\n",
        "vectorizer = CountVectorizer(analyzer='word',       \n",
        "                             min_df=10,                        # minimum reqd occurences of a word \n",
        "                             stop_words=stopwords,             # remove stop words\n",
        "                             lowercase=True,                   # convert all words to lowercase\n",
        "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
        "                             max_features=50000,             # max number of uniq words\n",
        "                            )\n",
        "\n",
        "data_vectorized = vectorizer.fit_transform(data_lemmatized)\n",
        "print(data_vectorized.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJiV6Ps7RFjA",
        "outputId": "263fcff1-f13a-4cdf-db11-95308dfc64ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sparsicity:  4.0525963296205 %\n"
          ]
        }
      ],
      "source": [
        "#SPARSE DATA\n",
        "# Materialize the sparse data\n",
        "data_dense = data_vectorized.todense()\n",
        "\n",
        "# Compute Sparsicity = Percentage of Non-Zero cells\n",
        "print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3agAHw9RP1D",
        "outputId": "c8509317-b548-4084-dc88-2646072f7596"
      },
      "outputs": [],
      "source": [
        "# Manually build and fit LDA model  ** JUST TO SEE HOW IT WORKS ** we will use GridSearchCV to find the best model\n",
        "#lda_model = LatentDirichletAllocation(n_components=3,               # Number of topics\n",
        "#                                      max_iter=10,               # Max learning iterations\n",
        "#                                      learning_method='online',   \n",
        "#                                      random_state=100,          # Random state\n",
        "#                                      batch_size=128,            # n docs in each learning iter\n",
        "#                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
        "#                                      n_jobs = -1,               # Use all available CPUs\n",
        "#                                     )\n",
        "#lda_output = lda_model.fit_transform(data_vectorized)\n",
        "#\n",
        "#print(lda_model)  # Model attributes\n",
        "#MODEL PERFORMANCE AND LOG_LIKELIHOOD\n",
        "# Log Likelyhood: Higher the better\n",
        "#print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
        "\n",
        "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
        "#print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
        "\n",
        "# See model parameters\n",
        "# higher log-likelihood and lower perplexity\n",
        "#pprint(lda_model.get_params())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x05Xp-u3XJfe",
        "outputId": "e8663762-afd6-45d4-fd4e-f02ffe8b92e8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LatentDirichletAllocation(),\n",
              "             param_grid={&#x27;batch_size&#x27;: [128], &#x27;evaluate_every&#x27;: [20],\n",
              "                         &#x27;learning_decay&#x27;: [0.5], &#x27;max_iter&#x27;: [100],\n",
              "                         &#x27;n_components&#x27;: [4], &#x27;n_jobs&#x27;: [-1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LatentDirichletAllocation(),\n",
              "             param_grid={&#x27;batch_size&#x27;: [128], &#x27;evaluate_every&#x27;: [20],\n",
              "                         &#x27;learning_decay&#x27;: [0.5], &#x27;max_iter&#x27;: [100],\n",
              "                         &#x27;n_components&#x27;: [4], &#x27;n_jobs&#x27;: [-1]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(estimator=LatentDirichletAllocation(),\n",
              "             param_grid={'batch_size': [128], 'evaluate_every': [20],\n",
              "                         'learning_decay': [0.5], 'max_iter': [100],\n",
              "                         'n_components': [4], 'n_jobs': [-1]})"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#GRID SEARCH TO FIND BEST n_components\n",
        "#TARDA 11 min maomenos\n",
        "# Define Search Param\n",
        "search_params = {'n_components': [4], \n",
        "                 'learning_decay': [0.5],\n",
        "                 'max_iter':[100],            # Max learning iterations\n",
        "                 'evaluate_every': [20],\n",
        "                 'batch_size':[128],          # n docs in each learning iter\n",
        "                 'n_jobs':[-1],               # Use all available CPUs\n",
        "                 }\n",
        "\n",
        "# Init the Model\n",
        "lda = LatentDirichletAllocation()\n",
        "\n",
        "# Init Grid Search Class\n",
        "model = GridSearchCV(estimator=lda, param_grid=search_params)\n",
        "\n",
        "# Do the Grid Search\n",
        "model.fit(data_vectorized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUP1nxp0ZT-L",
        "outputId": "a9453d95-881a-4be3-a8e3-34abaa36058d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Model's Params:  {'batch_size': 128, 'evaluate_every': 20, 'learning_decay': 0.5, 'max_iter': 100, 'n_components': 4, 'n_jobs': -1}\n",
            "Best Log Likelihood Score:  -61432.13843389174\n",
            "Model Perplexity:  546.9265849021027\n"
          ]
        }
      ],
      "source": [
        "#GET BEST MODEL\n",
        "# Best Model\n",
        "best_lda_model = model.best_estimator_\n",
        "\n",
        "# Model Parameters\n",
        "print(\"Best Model's Params: \", model.best_params_)\n",
        "\n",
        "# Log Likelihood Score\n",
        "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
        "\n",
        "# Perplexity\n",
        "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vWVdU_xBDUQO",
        "outputId": "d739354f-3ebc-47c8-d71e-c25fb839fd66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nivalderramas/dev/horus/lda/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/home/nivalderramas/dev/horus/lda/venv/lib/python3.10/site-packages/pyLDAvis/_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n",
            "/home/nivalderramas/dev/horus/lda/venv/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
            "  from imp import reload\n",
            "/home/nivalderramas/dev/horus/lda/venv/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
            "  from imp import reload\n",
            "/home/nivalderramas/dev/horus/lda/venv/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
            "  from imp import reload\n",
            "/home/nivalderramas/dev/horus/lda/venv/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
            "  from imp import reload\n",
            "/home/nivalderramas/dev/horus/lda/venv/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
            "  from imp import reload\n",
            "/home/nivalderramas/dev/horus/lda/venv/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
            "  from imp import reload\n",
            "/home/nivalderramas/dev/horus/lda/venv/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
            "  from imp import reload\n",
            "/home/nivalderramas/dev/horus/lda/venv/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
            "  from imp import reload\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el3991404946314453123965668591\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el3991404946314453123965668591_data = {\"mdsDat\": {\"x\": [-0.16128014134038254, 0.10281142732171929, 0.1656842959173772, -0.10721558189871395], \"y\": [0.06812542852024475, 0.1968843373974627, -0.06323445528586016, -0.20177531063184725], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [29.305909967485583, 29.089771363146966, 22.364323658598515, 19.239995010768947]}, \"tinfo\": {\"Term\": [\"image\", \"network\", \"cluster\", \"algorithm\", \"emission\", \"oil\", \"production\", \"ethanol\", \"feature\", \"column\", \"representation\", \"reaction\", \"process\", \"temperature\", \"environment\", \"water\", \"distillation\", \"equilibrium\", \"catalyst\", \"product\", \"source\", \"learning\", \"visual\", \"classification\", \"design\", \"service\", \"genetic\", \"glycerol\", \"learn\", \"air\", \"emission\", \"air\", \"bogota\", \"innovation\", \"course\", \"colombian\", \"education\", \"vehicle\", \"business\", \"inventory\", \"country\", \"government\", \"supply\", \"developer\", \"road\", \"cycle\", \"indicator\", \"diesel\", \"sustainable\", \"organizational\", \"national\", \"survey\", \"urban\", \"pollutant\", \"life\", \"strategic\", \"science\", \"sustainability\", \"matter\", \"overview\", \"city\", \"factor\", \"source\", \"risk\", \"university\", \"environmental\", \"knowledge\", \"practice\", \"engineering\", \"policy\", \"project\", \"organization\", \"code\", \"management\", \"measurement\", \"development\", \"decision\", \"methodology\", \"impact\", \"region\", \"level\", \"identify\", \"process\", \"result\", \"description\", \"technology\", \"high\", \"analysis\", \"information\", \"base\", \"allow\", \"develop\", \"design\", \"paper\", \"such\", \"image\", \"cluster\", \"visual\", \"classification\", \"genetic\", \"text\", \"dataset\", \"retrieval\", \"operator\", \"classifier\", \"multimodal\", \"class\", \"query\", \"latent\", \"clustering\", \"convolutional\", \"sequence\", \"annotation\", \"book\", \"label\", \"kernel\", \"negative\", \"vector\", \"unsupervised\", \"outperform\", \"string\", \"supervised\", \"histopathology\", \"dimensional\", \"textual\", \"evolutionary\", \"semantic\", \"representation\", \"feature\", \"neural\", \"deep\", \"train\", \"learn\", \"algorithm\", \"search\", \"evolve\", \"learning\", \"collection\", \"space\", \"problem\", \"datum\", \"good\", \"base\", \"paper\", \"result\", \"description\", \"strategy\", \"fuzzy\", \"document\", \"information\", \"experiment\", \"network\", \"fault\", \"computing\", \"robot\", \"patient\", \"immune\", \"protocol\", \"diagnosis\", \"hardware\", \"virtual\", \"intelligent\", \"game\", \"failure\", \"question\", \"inspire\", \"fpga\", \"programming\", \"eye\", \"educational\", \"cognitive\", \"radio\", \"platform\", \"processor\", \"recommendation\", \"feedback\", \"orient\", \"clinical\", \"thing\", \"reliability\", \"wireless\", \"record\", \"environment\", \"interval\", \"distribute\", \"artificial\", \"network\", \"node\", \"agent\", \"sensor\", \"service\", \"architecture\", \"device\", \"resource\", \"communication\", \"tool\", \"software\", \"user\", \"design\", \"base\", \"paper\", \"implementation\", \"implement\", \"concept\", \"allow\", \"control\", \"description\", \"information\", \"result\", \"ieee\", \"develop\", \"problem\", \"such\", \"algorithm\", \"oil\", \"ethanol\", \"column\", \"reaction\", \"temperature\", \"water\", \"distillation\", \"equilibrium\", \"catalyst\", \"glycerol\", \"separation\", \"mixture\", \"liquid\", \"chemical\", \"alcohol\", \"acid\", \"solvent\", \"reactor\", \"biodiesel\", \"composition\", \"thermodynamic\", \"ethylene\", \"vapor\", \"glycol\", \"oxide\", \"hydrogen\", \"kinetic\", \"formation\", \"conversion\", \"azeotropic\", \"extractive\", \"particle\", \"pressure\", \"material\", \"production\", \"phase\", \"mass\", \"product\", \"process\", \"condition\", \"flow\", \"produce\", \"high\", \"energy\", \"design\", \"datum\", \"result\", \"variable\", \"description\"], \"Freq\": [343.0, 399.0, 200.0, 294.0, 162.0, 109.0, 152.0, 107.0, 174.0, 94.0, 163.0, 92.0, 399.0, 87.0, 106.0, 84.0, 83.0, 83.0, 82.0, 124.0, 157.0, 176.0, 103.0, 102.0, 269.0, 117.0, 97.0, 71.0, 140.0, 94.0, 161.96493140327578, 93.34565416013834, 80.59130404983777, 73.75262618283611, 64.92350160202894, 65.89090048049673, 62.97192833753518, 62.95263503306717, 55.12098026479525, 46.31132603877447, 46.29022352309769, 40.42971868782041, 39.418046544048806, 37.475403929107614, 36.500016012260936, 37.42934253440871, 35.428408860350814, 39.25559088288103, 28.66614108789271, 28.663496252479042, 28.644181486597766, 27.659997497408305, 25.72449290831724, 24.739326624943054, 23.728971477733637, 21.797331282965295, 20.79172724085735, 19.832516254983556, 19.81387208199864, 18.846254800544727, 70.68881726724567, 80.5988927622762, 141.47792936890744, 48.36996480346164, 41.620610846943144, 54.826324886641444, 109.93098004476994, 45.64465887695314, 101.21138496304555, 43.18661392542636, 106.19449220500726, 42.58502134283449, 80.23198556059803, 86.10462211886181, 69.06000143085966, 103.27886805297388, 66.38363863318935, 78.79830988098968, 62.84847968633573, 64.85639188984766, 89.0863312952014, 73.46992821965904, 146.61886807976074, 149.6366135644928, 134.82232947886263, 73.52757199050123, 95.85464193986707, 90.94051279547891, 94.80793674513501, 106.49618714283326, 74.14515712813876, 70.09318516478592, 71.32201155293323, 72.12778973725611, 69.67329954334733, 342.3087482270195, 199.61591078747838, 102.85700029138582, 101.87953968320754, 96.99135243422668, 87.22391436504054, 76.47015139822025, 71.58245328680052, 67.68163308888036, 54.9695992107821, 53.997361681217214, 54.94757724275184, 50.080811734386536, 49.11158788386575, 45.20145448216397, 43.23636168245369, 39.31193175623692, 34.45030236732251, 34.44930924429475, 33.4720225836905, 32.49084387065561, 29.527839053919863, 28.5709752726761, 26.63150315567404, 26.629283015004255, 26.62927751478504, 24.67195952367176, 23.70018091901628, 23.655955097035314, 21.743240312151485, 95.81126592385726, 67.50989779010096, 153.05533078085847, 163.3018292227485, 107.35266999576169, 51.35952183094766, 47.81047110371465, 122.30580410360062, 237.0259194021069, 91.04615654173304, 56.684501420923006, 139.17574987444902, 75.7338682053651, 90.6398477782597, 172.27745298448002, 184.68108073665442, 87.6749293400073, 228.65008068084643, 177.69203491998198, 192.40975312037438, 178.5008730024211, 104.20547535280713, 75.48448071409838, 72.38372814674148, 101.25280362305485, 70.07179049221597, 72.91180576280013, 54.79813255033386, 49.91060766877053, 47.004379566884545, 47.9576343629545, 42.12323235078186, 35.29361328404559, 35.28946349427586, 34.33046939288507, 36.23536941906684, 33.3571266610501, 33.35355128397138, 32.38634205168821, 36.18960073162332, 29.457839361748626, 27.520220414508866, 65.47099555264373, 27.48121213552307, 24.562792389679124, 22.641079545760373, 22.640060280537888, 50.860432287573595, 20.66361108163134, 19.696352848782446, 19.69352041853996, 18.72827053126928, 19.65511522489848, 16.801275203233644, 15.827702263708959, 14.848387332510878, 15.776263630604404, 100.18651972291289, 35.139044080550505, 35.12820590699312, 43.39295299963331, 319.80377022822154, 32.53388284153323, 88.43323319167646, 43.85452919874862, 96.35844726438309, 81.34039961995937, 44.19319859215725, 48.6202674655291, 62.007590174160946, 77.35464181078292, 94.16640361046427, 57.327154256126356, 126.92695929599267, 188.59570496193322, 130.60510283416565, 65.25230977855905, 55.823912188104565, 48.31097465854851, 81.36584448002965, 59.66956258261592, 106.60689585552751, 81.81382569464188, 84.51354259429733, 52.70634788406791, 55.1898606140405, 59.711523630060796, 54.27876201415717, 55.30186663022081, 109.06948600692293, 107.1171373319904, 93.38962524736237, 91.42746310706998, 86.51675042996837, 83.57703842916855, 82.60506485326336, 82.60213071041098, 81.6237323356204, 70.83935542871495, 61.024503693018175, 61.01892371109465, 54.17059343749897, 53.16991663592361, 49.26873118555159, 45.34442035065052, 44.366225411766045, 43.384918005853315, 36.52023884035103, 32.585180326882245, 31.606440766621063, 30.637622877154225, 28.67886891694628, 26.7177872194513, 24.750512873049495, 23.775811944951194, 23.775083515543457, 24.682634021271106, 21.797861658602837, 20.834932764619303, 55.50674334818475, 61.24329841356831, 43.76882655766153, 52.92976525799264, 120.71033435030277, 75.98911757141332, 50.092058878751445, 88.47880583926951, 175.72663976710112, 86.02499902199072, 49.68595389611082, 56.04985986769242, 73.0071013956649, 52.54808004951154, 71.26385806210651, 72.00822912870993, 70.31805693834123, 52.71897518684855, 57.24552000752761], \"Total\": [343.0, 399.0, 200.0, 294.0, 162.0, 109.0, 152.0, 107.0, 174.0, 94.0, 163.0, 92.0, 399.0, 87.0, 106.0, 84.0, 83.0, 83.0, 82.0, 124.0, 157.0, 176.0, 103.0, 102.0, 269.0, 117.0, 97.0, 71.0, 140.0, 94.0, 162.70481815186665, 94.09344473908219, 81.35133173197543, 74.49019821896363, 65.66870904207644, 66.64888268045686, 63.70841984318219, 63.70835988149563, 55.867094804237524, 47.04567792708528, 47.045612108679094, 41.16469574496728, 40.18447524989123, 38.22414014085754, 37.2439953070146, 38.22407477683162, 36.26348864042732, 40.18460634081472, 29.402744366924193, 29.402729346801422, 29.402733541922984, 28.42246511666619, 26.462254661901227, 25.482110590827755, 24.50185201647435, 22.541578483095336, 21.561369898664953, 20.581220786507654, 20.581305440365742, 19.601031690329208, 74.47165406626077, 87.23411061970178, 157.7419987536229, 51.93834730131485, 45.07751524122969, 60.76961151094566, 130.30313757890497, 49.96441182598062, 123.50520782635846, 47.04030288493485, 138.10723134019776, 47.02317135488088, 100.86492906392293, 111.5854390923514, 86.25729092815084, 151.66264150201556, 85.17171613097103, 108.69958923322602, 79.3360587176358, 88.1520565521601, 150.74283749558253, 113.54284500669486, 399.61265881001793, 496.87796621750573, 477.17561834433883, 128.15617653353019, 235.00548063558563, 238.71503052830337, 283.4595224736137, 566.7020553622895, 223.88061000031692, 155.50768177570646, 269.77282166911954, 397.62549377438256, 210.2272925261161, 343.0540938249713, 200.35951232627787, 103.60086913003218, 102.6235031272132, 97.73668233980972, 87.9631078527305, 77.2121358788929, 72.32534209651695, 68.41590457467744, 55.710214698694294, 54.73286384786814, 55.710212010300054, 50.82339960973301, 49.84606149342925, 45.93662029631615, 43.98187306299923, 40.072519688359655, 35.18565702137906, 35.185666356885385, 34.208301524654836, 33.23092847801884, 30.298890090460578, 29.32152358418245, 27.36677435033717, 27.36677702058564, 27.36678210109907, 25.41204704830511, 24.43469662930997, 24.434802931781146, 22.4799834874211, 99.68143190586515, 70.3766940815562, 163.23179338877856, 174.91318488638933, 117.25438909401161, 54.73069703419756, 50.829861652682176, 140.68412122605238, 294.99290179604225, 106.57550894755167, 62.5353723919608, 176.7863543709897, 87.96234816411975, 116.3452470985289, 301.0371852791176, 339.33212139739044, 127.13348540000183, 566.7020553622895, 397.62549377438256, 496.87796621750573, 477.17561834433883, 211.18625073202298, 117.15197304492497, 107.49775094275276, 283.4595224736137, 110.42516635936516, 399.7068742041532, 55.53437647556353, 50.66333087798899, 47.74061526175825, 48.7149194805936, 42.869550396530656, 36.050104729900816, 36.050063382617246, 35.075796533825006, 37.02448807999367, 34.10158829633541, 34.10160320277592, 33.127345726870594, 37.02467127974059, 30.204692724175718, 28.256217202451296, 67.23153223273681, 28.25634980184051, 25.333770045777197, 23.385159892732876, 23.385168811332452, 52.61822676110806, 21.436914481795913, 20.462587906556045, 20.462645079374628, 19.488385416716007, 20.46287176109649, 17.53981587249127, 16.56558663267244, 15.591383943797236, 16.56581959041455, 106.22594629327219, 37.03120627801879, 37.03163944245892, 46.77839836100974, 399.7068742041532, 35.08676072076697, 103.36173668866373, 48.74133161954715, 117.03150214183508, 99.4300318687388, 50.699254674765456, 57.533351381043616, 83.91510586676671, 113.2288503445244, 152.3314861666256, 79.97569945967155, 269.77282166911954, 566.7020553622895, 397.62549377438256, 117.21710693034116, 90.81381580192118, 71.20092488430075, 223.88061000031692, 120.20275515047828, 477.17561834433883, 283.4595224736137, 496.87796621750573, 110.31244693617205, 155.50768177570646, 301.0371852791176, 210.2272925261161, 294.99290179604225, 109.81118338467245, 107.85023054233254, 94.12352839100365, 92.16256343984843, 87.26014366694332, 84.3187300202885, 83.33826338388062, 83.33825320336027, 82.35778450144171, 71.57251962370658, 61.7676943173009, 61.76767971605897, 54.90438038002844, 53.923884056163295, 50.00198876852446, 46.08006835117389, 45.09959471480513, 44.11911309615758, 37.255764774230535, 33.333800560770854, 32.35332651032995, 31.372891566841, 29.411936123888115, 27.450979348373266, 25.490017564761484, 24.509542772716237, 24.50953688811772, 25.489832241093595, 22.54848043899079, 21.56810677169892, 57.840711730583074, 64.70824720872551, 46.07943321901171, 57.84443583949862, 152.94202147355213, 92.14835240882337, 59.80382621029905, 124.5069107463666, 399.61265881001793, 142.02541337468705, 65.68455539637134, 86.20499604531166, 235.00548063558563, 82.23928375905335, 269.77282166911954, 339.33212139739044, 496.87796621750573, 99.95671587812984, 477.17561834433883], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.3727, -4.9238, -5.0707, -5.1594, -5.2869, -5.2721, -5.3174, -5.3177, -5.4505, -5.6247, -5.6251, -5.7605, -5.7859, -5.8364, -5.8628, -5.8376, -5.8926, -5.79, -6.1044, -6.1045, -6.1051, -6.1401, -6.2126, -6.2517, -6.2934, -6.3783, -6.4255, -6.4728, -6.4737, -6.5238, -5.2018, -5.0706, -4.5079, -5.5812, -5.7315, -5.4559, -4.7602, -5.6392, -4.8429, -5.6945, -4.7948, -5.7086, -5.0752, -5.0045, -5.2251, -4.8226, -5.2646, -5.0932, -5.3193, -5.2879, -4.9705, -5.1632, -4.4722, -4.4519, -4.5561, -5.1624, -4.8972, -4.9499, -4.9082, -4.792, -5.1541, -5.2103, -5.1929, -5.1816, -5.2163, -3.617, -4.1563, -4.8193, -4.8289, -4.8781, -4.9842, -5.1158, -5.1818, -5.2379, -5.4459, -5.4637, -5.4463, -5.539, -5.5586, -5.6415, -5.686, -5.7811, -5.9132, -5.9132, -5.942, -5.9717, -6.0673, -6.1003, -6.1706, -6.1707, -6.1707, -6.247, -6.2872, -6.2891, -6.3734, -4.8903, -5.2404, -4.4219, -4.3571, -4.7766, -5.5138, -5.5854, -4.6461, -3.9845, -4.9413, -5.4152, -4.5169, -5.1254, -4.9458, -4.3036, -4.234, -4.979, -4.0205, -4.2726, -4.193, -4.2681, -4.8063, -5.1287, -5.1707, -4.8351, -5.2032, -5.1634, -5.1861, -5.2795, -5.3395, -5.3194, -5.4492, -5.6261, -5.6262, -5.6537, -5.5997, -5.6825, -5.6826, -5.712, -5.601, -5.8068, -5.8748, -5.0081, -5.8763, -5.9885, -6.07, -6.07, -5.2607, -6.1614, -6.2093, -6.2095, -6.2597, -6.2114, -6.3683, -6.428, -6.4919, -6.4312, -4.5827, -5.6304, -5.6308, -5.4195, -3.422, -5.7075, -4.7075, -5.4089, -4.6217, -4.7911, -5.4012, -5.3057, -5.0625, -4.8414, -4.6447, -5.141, -4.3461, -3.9501, -4.3176, -5.0115, -5.1676, -5.3121, -4.7908, -5.1009, -4.5206, -4.7853, -4.7528, -5.225, -5.179, -5.1002, -5.1956, -5.1769, -4.3473, -4.3654, -4.5025, -4.5237, -4.5789, -4.6135, -4.6252, -4.6252, -4.6372, -4.7789, -4.928, -4.9281, -5.0471, -5.0658, -5.142, -5.225, -5.2468, -5.2692, -5.4414, -5.5554, -5.5859, -5.617, -5.6831, -5.7539, -5.8304, -5.8706, -5.8706, -5.8332, -5.9575, -6.0026, -5.0228, -4.9244, -5.2604, -5.0703, -4.2459, -4.7087, -5.1254, -4.5565, -3.8703, -4.5846, -5.1336, -5.013, -4.7487, -5.0776, -4.7729, -4.7625, -4.7862, -5.0743, -4.9919], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2228, 1.2194, 1.218, 1.2174, 1.216, 1.2159, 1.2158, 1.2154, 1.2139, 1.2116, 1.2112, 1.2094, 1.2081, 1.2076, 1.2072, 1.2064, 1.2041, 1.204, 1.202, 1.2019, 1.2012, 1.2002, 1.1991, 1.1978, 1.1953, 1.1938, 1.191, 1.1903, 1.1894, 1.1881, 1.1752, 1.1483, 1.1186, 1.1562, 1.1476, 1.1245, 1.0574, 1.137, 1.0283, 1.1419, 0.9646, 1.1282, 0.9985, 0.9682, 1.005, 0.8432, 0.9782, 0.9057, 0.9944, 0.9205, 0.7014, 0.7921, 0.2247, 0.0272, -0.0365, 0.6718, 0.3306, 0.2623, 0.1322, -0.4443, 0.1223, 0.4305, -0.103, -0.4797, 0.123, 1.2326, 1.2311, 1.2276, 1.2275, 1.2271, 1.2263, 1.2251, 1.2245, 1.224, 1.2214, 1.2213, 1.221, 1.2201, 1.2199, 1.2187, 1.2177, 1.2156, 1.2137, 1.2136, 1.213, 1.2123, 1.209, 1.2089, 1.2075, 1.2075, 1.2075, 1.2052, 1.2043, 1.2024, 1.2015, 1.1952, 1.1932, 1.1704, 1.1661, 1.1466, 1.1712, 1.1735, 1.0948, 1.016, 1.0773, 1.1366, 0.9956, 1.0851, 0.9851, 0.6767, 0.6264, 0.8632, 0.3271, 0.4293, 0.2861, 0.2515, 0.5284, 0.7952, 0.8393, 0.2053, 0.78, -0.4667, 1.4844, 1.4827, 1.4822, 1.482, 1.4801, 1.4765, 1.4764, 1.4762, 1.4762, 1.4756, 1.4755, 1.4751, 1.4749, 1.4727, 1.4713, 1.4712, 1.4699, 1.4668, 1.4654, 1.4653, 1.4637, 1.461, 1.4595, 1.4594, 1.4579, 1.4574, 1.4547, 1.4521, 1.4489, 1.4489, 1.4392, 1.4453, 1.4449, 1.4226, 1.2747, 1.4222, 1.3417, 1.3921, 1.3033, 1.2969, 1.3604, 1.3294, 1.1952, 1.1167, 1.0167, 1.1648, 0.7437, 0.3975, 0.3844, 0.9119, 1.0111, 1.1099, 0.4855, 0.7973, -0.001, 0.2551, -0.2737, 0.7591, 0.4618, -0.12, 0.1436, -0.1764, 1.6414, 1.6414, 1.6404, 1.6402, 1.6396, 1.6393, 1.6393, 1.6393, 1.6392, 1.6379, 1.6361, 1.636, 1.6347, 1.6341, 1.6334, 1.6321, 1.6318, 1.6314, 1.6282, 1.6255, 1.6248, 1.6245, 1.6229, 1.6211, 1.6187, 1.6178, 1.6178, 1.616, 1.6143, 1.6136, 1.607, 1.5931, 1.5967, 1.5594, 1.4115, 1.4554, 1.471, 1.3066, 0.8266, 1.1468, 1.369, 1.2177, 0.4791, 1.2003, 0.317, 0.098, -0.3071, 1.0084, -0.4724]}, \"token.table\": {\"Topic\": [4, 3, 4, 1, 4, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 2, 3, 2, 3, 4, 4, 1, 2, 3, 4, 4, 1, 2, 1, 4, 4, 1, 3, 2, 2, 2, 3, 2, 2, 1, 3, 4, 3, 1, 2, 3, 1, 4, 1, 3, 4, 3, 2, 3, 4, 1, 3, 4, 1, 2, 3, 4, 4, 2, 1, 1, 1, 2, 1, 2, 3, 4, 1, 2, 3, 2, 3, 4, 1, 2, 3, 4, 1, 3, 4, 1, 2, 3, 4, 1, 1, 3, 4, 1, 3, 4, 3, 1, 2, 4, 3, 4, 1, 2, 3, 1, 3, 1, 1, 3, 4, 1, 4, 1, 3, 1, 4, 4, 4, 4, 2, 3, 2, 3, 1, 2, 3, 4, 2, 4, 3, 1, 4, 3, 3, 2, 3, 3, 1, 4, 4, 3, 2, 3, 3, 2, 4, 4, 1, 2, 3, 4, 1, 3, 1, 2, 3, 4, 2, 4, 1, 2, 3, 4, 1, 2, 3, 2, 3, 1, 2, 3, 4, 1, 3, 1, 2, 3, 1, 1, 2, 3, 4, 1, 3, 3, 1, 3, 1, 2, 4, 1, 2, 2, 2, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 4, 1, 3, 1, 4, 1, 4, 1, 1, 4, 1, 2, 3, 4, 4, 2, 1, 2, 1, 2, 3, 2, 3, 1, 3, 4, 2, 1, 3, 1, 3, 2, 1, 4, 1, 2, 3, 4, 1, 4, 3, 1, 2, 4, 3, 4, 1, 2, 4, 1, 1, 3, 1, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 4, 1, 4, 3, 4, 1, 2, 3, 4, 3, 2, 3, 3, 4, 4, 3, 3, 1, 2, 4, 3, 2, 3, 4, 1, 3, 4, 1, 2, 3, 4, 2, 1, 2, 1, 3, 1, 1, 2, 4, 1, 2, 3, 4, 4, 2, 1, 3, 4, 1, 3, 4, 4, 1, 2, 3, 1, 2, 3, 4, 1, 1, 2, 3, 4, 2, 1, 2, 3, 4, 2, 1, 1, 1, 1, 1, 3, 4, 4, 2, 2, 4, 3, 1, 3, 4, 1, 2, 1, 2, 2, 1, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 3, 2, 4, 3], \"Freq\": [0.9765610514519478, 0.8513788837068899, 0.13544664058973246, 0.9883791613526929, 0.9799610216872974, 0.8034091619053991, 0.18644516415526138, 0.0067798241511004146, 0.3305333141619332, 0.14293332504299816, 0.36179997901508903, 0.16079999067337292, 0.38120766756331476, 0.27648028636460187, 0.1843201909097346, 0.1591856194220435, 0.9663028312741568, 0.18103182370254547, 0.8146432066614546, 0.04275477720645989, 0.9192277099388876, 0.021377388603229946, 0.9736598683550486, 0.18704714231578848, 0.4040924112293921, 0.3335085839404153, 0.07587761433565005, 0.993134894001493, 0.9956813032497986, 0.9663025748934447, 0.9844793288916152, 0.9956557294054522, 0.9828668859386864, 0.9533828795695624, 0.04028378364378433, 0.9872516728141557, 0.9939243632480534, 0.9872516251725927, 0.977379921718686, 0.9982056637985203, 0.9796105962895302, 0.7931399024660016, 0.14871373171237529, 0.0495712439041251, 0.9835297302007088, 0.06821100306241515, 0.8640060387905919, 0.06821100306241515, 0.990264162663193, 0.9880632567625777, 0.25025291671969074, 0.7388419446009917, 0.9899861235396096, 0.9869070811868554, 0.2808952275900821, 0.6741485462161971, 0.04213428413851232, 0.24643476944273404, 0.14786086166564044, 0.6055254334878608, 0.09983132237674215, 0.024957830594185538, 0.49915661188371074, 0.38268673577751156, 0.9756755032573122, 0.9776755059614491, 0.9777745030447548, 0.98981693028794, 0.9679763399381597, 0.9843012259006262, 0.10903771752474165, 0.5451885876237083, 0.13556040557130042, 0.21218150437247024, 0.7749051328085238, 0.03522296058220563, 0.17611480291102813, 0.931835382402192, 0.03654256401577224, 0.01827128200788612, 0.282914706473082, 0.37512394413838274, 0.22423610068607236, 0.11945287606641238, 0.26318440664524234, 0.4707664738583912, 0.26318440664524234, 0.4501385346414151, 0.025722201979509435, 0.35368027721825473, 0.1736248633616887, 0.9679746846797198, 0.6791389031598211, 0.28352400811526507, 0.03296790792037966, 0.05917246750953107, 0.8678628568064557, 0.05917246750953107, 0.9708720794337474, 0.9705208922350065, 0.9822055887663568, 0.9959410795216301, 0.9451377396991631, 0.027003935419976092, 0.14884032325960658, 0.6697814546682297, 0.16744536366705742, 0.9888802791699125, 0.9868250937316441, 0.9956681175156794, 0.13375602871528, 0.21887350153409454, 0.6444608656281673, 0.8177792805466184, 0.17813014031708518, 0.056483375383966895, 0.9413895897327816, 0.9050576206183834, 0.08227796551076212, 0.9959412011848284, 0.9921165625881642, 0.9881142110842239, 0.9630680274603024, 0.03009587585813445, 0.9114841380128665, 0.07995474894849706, 0.04527953332420721, 0.6339134665389009, 0.19922994662651172, 0.11772678664293874, 0.03457772112687381, 0.9681761915524666, 0.955537434571302, 0.9285358608528782, 0.06878043413725024, 0.9659693313142148, 0.9903775551383264, 0.9318908697813304, 0.06288834090548855, 0.9773907489681795, 0.22836418560623548, 0.7612139520207849, 0.9807832300950217, 0.9909323601027151, 0.6401940833829516, 0.3499727655826802, 0.9676964394833423, 0.9924625808634631, 0.9920008457615211, 0.9835714659703028, 0.07079173493657612, 0.6921858527131888, 0.05506023828400365, 0.18091221150458342, 0.9717064410682623, 0.9693293769455079, 0.40850111129477734, 0.19148489591942686, 0.08935961809573253, 0.3106310533804036, 0.9822098618245769, 0.9792104333629816, 0.6429291074721236, 0.19375945704639344, 0.13210872071345006, 0.026421744142690013, 0.12691224235194917, 0.3898018872238439, 0.48045348890380757, 0.9969273247457321, 0.9797163630481875, 0.7940903672089723, 0.03781382700995106, 0.10083687202653617, 0.06302304501658511, 0.3743923730080806, 0.616646261425074, 0.4265588983501666, 0.01706235593400666, 0.5545265678552166, 0.9651581056374495, 0.33514485303221114, 0.3563118963816139, 0.28928292577517173, 0.02116704334940281, 0.9934192923272577, 0.9601157099932526, 0.9676968624815113, 0.027004251292607393, 0.9451487952412587, 0.9777731351069923, 0.9629583483099771, 0.9792106684657619, 0.8441853515107385, 0.15348824572922518, 0.9646781199065385, 0.9830265126655839, 0.8671909732013708, 0.127946209160858, 0.005656545176000858, 0.7862597794641193, 0.20929217151203175, 0.5904094780132297, 0.23881731694917158, 0.11277484411488659, 0.059704329237292894, 0.9795177925269928, 0.983528083301029, 0.7707098766607341, 0.22404356879672502, 0.15049204324070614, 0.8360669068928119, 0.06915098992578697, 0.9162506165166774, 0.9717556574800333, 0.799932379715872, 0.19708478920535977, 0.7267736755701759, 0.06439766745558521, 0.11959566813180111, 0.09199666779369316, 0.9875714982400515, 0.9866101680718707, 0.9863028537347128, 0.9901352792274499, 0.017512833658259022, 0.1826338367218441, 0.8005866815204125, 0.9125457974473783, 0.07675618857034022, 0.057001557251657335, 0.940525694652346, 0.9926129255721537, 0.993920937284057, 0.9144427898212508, 0.08506444556476753, 0.986302994458396, 0.9749396675880035, 0.9865977268602092, 0.9693367318708155, 0.9807760993684482, 0.18107490874529705, 0.44765741328698433, 0.32945573674491546, 0.04275379789819513, 0.046361941937989454, 0.9426928194057855, 0.9853244244634665, 0.13022479172238546, 0.032556197930596366, 0.8247570142417746, 0.9692458894813204, 0.01900482136237883, 0.9141097604150673, 0.042516733042561275, 0.021258366521280637, 0.9810804293816506, 0.9206552888126025, 0.08005698163587847, 0.04340331163567413, 0.9548728559848308, 0.17273613541060154, 0.5713579863581436, 0.19931092547377102, 0.05647142888423512, 0.3678562146598216, 0.09258965947219999, 0.10009692915913512, 0.44042648830019454, 0.9796185928638687, 0.12760281311558908, 0.17400383606671238, 0.046401022951123305, 0.6496143213157263, 0.2891405768900307, 0.7067880768422973, 0.20922961323310138, 0.7911494750376646, 0.9668082496616042, 0.014873973071716987, 0.7675195496381473, 0.10137050655598172, 0.07240750468284408, 0.05792600374627527, 0.9708709659023588, 0.9837988088940174, 0.9723246353222513, 0.9835293551036587, 0.9873857302091299, 0.9746342793945456, 0.9773934798145528, 0.9658441535399825, 0.7373622640504037, 0.2382247314624381, 0.022688069663089346, 0.9658577359671087, 0.937317398918672, 0.018378772527817097, 0.042883802564906565, 0.0869061141056251, 0.851679918235126, 0.05214366846337506, 0.30188499027614013, 0.38641278755345937, 0.1710681611564794, 0.14087966212886538, 0.9955016860330534, 0.9241726488048042, 0.05776079055030026, 0.9934487343529268, 0.9844866837660656, 0.9739640894199532, 0.1313622626647716, 0.8538547073210155, 0.009383018761769401, 0.02841849885250784, 0.9662289609852666, 0.9027246186756684, 0.08206587442506078, 0.9875712647883981, 0.9732355315637613, 0.1623494499538522, 0.820291957661569, 0.01708941578461602, 0.3544900752883936, 0.6170753162427592, 0.026258524095436563, 0.9756185233645979, 0.8938646721487774, 0.06339465759920407, 0.03803679455952244, 0.13752173293723063, 0.7821548560804993, 0.051570649851461495, 0.03438043323430766, 0.9759742431746081, 0.26516877782474174, 0.4924563016745203, 0.17993595638107474, 0.06155703770931504, 0.9865975437030158, 0.3329729416141534, 0.3044324037615117, 0.25686484067377546, 0.10464863879301964, 0.9837853657549956, 0.9705240582955121, 0.9851362253438578, 0.9717596544667223, 0.9863024906145411, 0.5774204724392584, 0.3199221536487783, 0.10924171100202186, 0.9970187572927195, 0.9890510024459009, 0.9786484056943511, 0.9890791288426821, 0.969223401407657, 0.24728679938729098, 0.6800386983150503, 0.0706533712535117, 0.05902042426357257, 0.9443267882171611, 0.9317283744509752, 0.06655202674649822, 0.9865978231251558, 0.9825315466196176, 0.07502278867877302, 0.21256456792319023, 0.7127164924483437, 0.9859942534162671, 0.3701602206009998, 0.08003464229210806, 0.020008660573027016, 0.5302295051852159, 0.9890345539767279, 0.9888812098943803, 0.9723294464522995, 0.9942001535790398, 0.9962199380824188, 0.9620698235686442], \"Term\": [\"acid\", \"agent\", \"agent\", \"air\", \"alcohol\", \"algorithm\", \"algorithm\", \"algorithm\", \"allow\", \"allow\", \"allow\", \"allow\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"annotation\", \"architecture\", \"architecture\", \"artificial\", \"artificial\", \"artificial\", \"azeotropic\", \"base\", \"base\", \"base\", \"base\", \"biodiesel\", \"bogota\", \"book\", \"business\", \"catalyst\", \"chemical\", \"city\", \"city\", \"class\", \"classification\", \"classifier\", \"clinical\", \"cluster\", \"clustering\", \"code\", \"code\", \"code\", \"cognitive\", \"collection\", \"collection\", \"collection\", \"colombian\", \"column\", \"communication\", \"communication\", \"composition\", \"computing\", \"concept\", \"concept\", \"concept\", \"condition\", \"condition\", \"condition\", \"control\", \"control\", \"control\", \"control\", \"conversion\", \"convolutional\", \"country\", \"course\", \"cycle\", \"dataset\", \"datum\", \"datum\", \"datum\", \"datum\", \"decision\", \"decision\", \"decision\", \"deep\", \"deep\", \"deep\", \"description\", \"description\", \"description\", \"description\", \"design\", \"design\", \"design\", \"develop\", \"develop\", \"develop\", \"develop\", \"developer\", \"development\", \"development\", \"development\", \"device\", \"device\", \"device\", \"diagnosis\", \"diesel\", \"dimensional\", \"distillation\", \"distribute\", \"distribute\", \"document\", \"document\", \"document\", \"education\", \"educational\", \"emission\", \"energy\", \"energy\", \"energy\", \"engineering\", \"engineering\", \"environment\", \"environment\", \"environmental\", \"environmental\", \"equilibrium\", \"ethanol\", \"ethylene\", \"evolutionary\", \"evolutionary\", \"evolve\", \"evolve\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"extractive\", \"extractive\", \"eye\", \"factor\", \"factor\", \"failure\", \"fault\", \"feature\", \"feature\", \"feedback\", \"flow\", \"flow\", \"formation\", \"fpga\", \"fuzzy\", \"fuzzy\", \"game\", \"genetic\", \"glycerol\", \"glycol\", \"good\", \"good\", \"good\", \"good\", \"government\", \"hardware\", \"high\", \"high\", \"high\", \"high\", \"histopathology\", \"hydrogen\", \"identify\", \"identify\", \"identify\", \"identify\", \"ieee\", \"ieee\", \"ieee\", \"image\", \"immune\", \"impact\", \"impact\", \"impact\", \"impact\", \"implement\", \"implement\", \"implementation\", \"implementation\", \"implementation\", \"indicator\", \"information\", \"information\", \"information\", \"information\", \"innovation\", \"inspire\", \"intelligent\", \"interval\", \"interval\", \"inventory\", \"kernel\", \"kinetic\", \"knowledge\", \"knowledge\", \"label\", \"latent\", \"learn\", \"learn\", \"learning\", \"learning\", \"learning\", \"level\", \"level\", \"level\", \"level\", \"life\", \"liquid\", \"management\", \"management\", \"mass\", \"mass\", \"material\", \"material\", \"matter\", \"measurement\", \"measurement\", \"methodology\", \"methodology\", \"methodology\", \"methodology\", \"mixture\", \"multimodal\", \"national\", \"negative\", \"network\", \"network\", \"network\", \"neural\", \"neural\", \"node\", \"node\", \"oil\", \"operator\", \"organization\", \"organization\", \"organizational\", \"orient\", \"outperform\", \"overview\", \"oxide\", \"paper\", \"paper\", \"paper\", \"paper\", \"particle\", \"particle\", \"patient\", \"phase\", \"phase\", \"phase\", \"platform\", \"platform\", \"policy\", \"policy\", \"policy\", \"pollutant\", \"practice\", \"practice\", \"pressure\", \"pressure\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"process\", \"processor\", \"produce\", \"produce\", \"produce\", \"produce\", \"product\", \"product\", \"production\", \"production\", \"programming\", \"programming\", \"project\", \"project\", \"project\", \"project\", \"protocol\", \"query\", \"question\", \"radio\", \"reaction\", \"reactor\", \"recommendation\", \"record\", \"region\", \"region\", \"region\", \"reliability\", \"representation\", \"representation\", \"representation\", \"resource\", \"resource\", \"resource\", \"result\", \"result\", \"result\", \"result\", \"retrieval\", \"risk\", \"risk\", \"road\", \"robot\", \"science\", \"search\", \"search\", \"search\", \"semantic\", \"semantic\", \"sensor\", \"sensor\", \"separation\", \"sequence\", \"service\", \"service\", \"service\", \"software\", \"software\", \"software\", \"solvent\", \"source\", \"source\", \"source\", \"space\", \"space\", \"space\", \"space\", \"strategic\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"string\", \"such\", \"such\", \"such\", \"such\", \"supervised\", \"supply\", \"survey\", \"sustainability\", \"sustainable\", \"technology\", \"technology\", \"technology\", \"temperature\", \"text\", \"textual\", \"thermodynamic\", \"thing\", \"tool\", \"tool\", \"tool\", \"train\", \"train\", \"university\", \"university\", \"unsupervised\", \"urban\", \"user\", \"user\", \"user\", \"vapor\", \"variable\", \"variable\", \"variable\", \"variable\", \"vector\", \"vehicle\", \"virtual\", \"visual\", \"water\", \"wireless\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 3, 2]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el3991404946314453123965668591\", ldavis_el3991404946314453123965668591_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el3991404946314453123965668591\", ldavis_el3991404946314453123965668591_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el3991404946314453123965668591\", ldavis_el3991404946314453123965668591_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "3     -0.161280  0.068125       1        1  29.305910\n",
              "0      0.102811  0.196884       2        1  29.089771\n",
              "2      0.165684 -0.063234       3        1  22.364324\n",
              "1     -0.107216 -0.201775       4        1  19.239995, topic_info=            Term        Freq       Total Category  logprob  loglift\n",
              "440        image  343.000000  343.000000  Default  30.0000  30.0000\n",
              "596      network  399.000000  399.000000  Default  29.0000  29.0000\n",
              "136      cluster  200.000000  200.000000  Default  28.0000  28.0000\n",
              "34     algorithm  294.000000  294.000000  Default  27.0000  27.0000\n",
              "288     emission  162.000000  162.000000  Default  26.0000  26.0000\n",
              "..           ...         ...         ...      ...      ...      ...\n",
              "237       design   71.263858  269.772822   Topic4  -4.7729   0.3170\n",
              "220        datum   72.008229  339.332121   Topic4  -4.7625   0.0980\n",
              "771       result   70.318057  496.877966   Topic4  -4.7862  -0.3071\n",
              "949     variable   52.718975   99.956716   Topic4  -5.0743   1.0084\n",
              "236  description   57.245520  477.175618   Topic4  -4.9919  -0.4724\n",
              "\n",
              "[263 rows x 6 columns], token_table=      Topic      Freq      Term\n",
              "term                           \n",
              "10        4  0.976561      acid\n",
              "30        3  0.851379     agent\n",
              "30        4  0.135447     agent\n",
              "32        1  0.988379       air\n",
              "33        4  0.979961   alcohol\n",
              "...     ...       ...       ...\n",
              "955       1  0.988881   vehicle\n",
              "961       3  0.972329   virtual\n",
              "963       2  0.994200    visual\n",
              "967       4  0.996220     water\n",
              "974       3  0.962070  wireless\n",
              "\n",
              "[381 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 3, 2])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "#panel = pyLDAvis.sklearn.prepare(best_lda_model, data_vectorized, vectorizer, mds='tsne')\n",
        "panel = pyLDAvis.sklearn.prepare(best_lda_model, data_vectorized, vectorizer, mds=\"mmds\")\n",
        "panel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4, 982)\n",
            "[[ 8.52775855  4.88021937  3.99403806 ...  0.25757609  4.85945873\n",
            "   0.25005046]\n",
            " [ 2.77179111 17.38804377  0.25007201 ... 12.68320144 24.80610075\n",
            "   8.7742931 ]\n",
            " [12.99706665  5.10367954  0.25609241 ...  5.95479547  5.07188108\n",
            "   0.25187691]\n",
            " [ 6.70338368 13.62805731 34.49979752 ... 37.10442699  0.26255944\n",
            "   8.72377954]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nivalderramas/dev/horus/lda/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# Show top n keywords for each topic\n",
        "def show_topics(vectorizer=vectorizer, lda_model=best_lda_model, n_words=20):\n",
        "    keywords = np.array(vectorizer.get_feature_names())\n",
        "    topic_keywords = []\n",
        "    print(lda_model.components_.shape)\n",
        "    print(lda_model.components_)\n",
        "    for topic_weights in lda_model.components_:\n",
        "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
        "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
        "    return topic_keywords\n",
        "\n",
        "topic_keywords = show_topics(vectorizer=vectorizer, lda_model=best_lda_model, n_words=20)        \n",
        "\n",
        "# Topic - Keywords Dataframe\n",
        "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
        "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
        "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
        "df_topic_keywords\n",
        "df_n_relevant_topic_keywords = df_topic_keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "bbXgRnuuk0_y",
        "outputId": "334cc781-3803-42af-b90f-b319eab8f337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len topicnames 4\n",
            "len docsnames 742\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_c361c_row0_col0, #T_c361c_row0_col2, #T_c361c_row0_col3, #T_c361c_row1_col0, #T_c361c_row1_col1, #T_c361c_row1_col3, #T_c361c_row2_col0, #T_c361c_row2_col1, #T_c361c_row2_col2, #T_c361c_row3_col0, #T_c361c_row3_col1, #T_c361c_row3_col3, #T_c361c_row4_col0, #T_c361c_row4_col1, #T_c361c_row4_col3, #T_c361c_row5_col0, #T_c361c_row5_col1, #T_c361c_row6_col0, #T_c361c_row6_col1, #T_c361c_row6_col2, #T_c361c_row7_col0, #T_c361c_row7_col1, #T_c361c_row7_col3, #T_c361c_row8_col0, #T_c361c_row8_col1, #T_c361c_row9_col0, #T_c361c_row9_col1, #T_c361c_row9_col3, #T_c361c_row10_col1, #T_c361c_row11_col0, #T_c361c_row11_col1, #T_c361c_row12_col0, #T_c361c_row12_col1, #T_c361c_row12_col2, #T_c361c_row13_col0, #T_c361c_row14_col0, #T_c361c_row14_col2, #T_c361c_row14_col3 {\n",
              "  color: black;\n",
              "  font-weight: 400;\n",
              "}\n",
              "#T_c361c_row0_col1, #T_c361c_row0_col4, #T_c361c_row1_col2, #T_c361c_row1_col4, #T_c361c_row2_col3, #T_c361c_row2_col4, #T_c361c_row3_col2, #T_c361c_row3_col4, #T_c361c_row4_col2, #T_c361c_row4_col4, #T_c361c_row5_col2, #T_c361c_row5_col3, #T_c361c_row5_col4, #T_c361c_row6_col3, #T_c361c_row6_col4, #T_c361c_row7_col2, #T_c361c_row7_col4, #T_c361c_row8_col2, #T_c361c_row8_col3, #T_c361c_row8_col4, #T_c361c_row9_col2, #T_c361c_row9_col4, #T_c361c_row10_col0, #T_c361c_row10_col2, #T_c361c_row10_col3, #T_c361c_row10_col4, #T_c361c_row11_col2, #T_c361c_row11_col3, #T_c361c_row11_col4, #T_c361c_row12_col3, #T_c361c_row12_col4, #T_c361c_row13_col1, #T_c361c_row13_col2, #T_c361c_row13_col3, #T_c361c_row13_col4, #T_c361c_row14_col1, #T_c361c_row14_col4 {\n",
              "  color: green;\n",
              "  font-weight: 700;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_c361c\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_c361c_level0_col0\" class=\"col_heading level0 col0\" >Topic0</th>\n",
              "      <th id=\"T_c361c_level0_col1\" class=\"col_heading level0 col1\" >Topic1</th>\n",
              "      <th id=\"T_c361c_level0_col2\" class=\"col_heading level0 col2\" >Topic2</th>\n",
              "      <th id=\"T_c361c_level0_col3\" class=\"col_heading level0 col3\" >Topic3</th>\n",
              "      <th id=\"T_c361c_level0_col4\" class=\"col_heading level0 col4\" >dominant_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row0\" class=\"row_heading level0 row0\" >Doc0</th>\n",
              "      <td id=\"T_c361c_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
              "      <td id=\"T_c361c_row0_col1\" class=\"data row0 col1\" >0.990000</td>\n",
              "      <td id=\"T_c361c_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
              "      <td id=\"T_c361c_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
              "      <td id=\"T_c361c_row0_col4\" class=\"data row0 col4\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row1\" class=\"row_heading level0 row1\" >Doc1</th>\n",
              "      <td id=\"T_c361c_row1_col0\" class=\"data row1 col0\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row1_col1\" class=\"data row1 col1\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row1_col2\" class=\"data row1 col2\" >0.980000</td>\n",
              "      <td id=\"T_c361c_row1_col3\" class=\"data row1 col3\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row1_col4\" class=\"data row1 col4\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row2\" class=\"row_heading level0 row2\" >Doc2</th>\n",
              "      <td id=\"T_c361c_row2_col0\" class=\"data row2 col0\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row2_col1\" class=\"data row2 col1\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row2_col2\" class=\"data row2 col2\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row2_col3\" class=\"data row2 col3\" >0.980000</td>\n",
              "      <td id=\"T_c361c_row2_col4\" class=\"data row2 col4\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row3\" class=\"row_heading level0 row3\" >Doc3</th>\n",
              "      <td id=\"T_c361c_row3_col0\" class=\"data row3 col0\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row3_col1\" class=\"data row3 col1\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row3_col2\" class=\"data row3 col2\" >0.880000</td>\n",
              "      <td id=\"T_c361c_row3_col3\" class=\"data row3 col3\" >0.100000</td>\n",
              "      <td id=\"T_c361c_row3_col4\" class=\"data row3 col4\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row4\" class=\"row_heading level0 row4\" >Doc4</th>\n",
              "      <td id=\"T_c361c_row4_col0\" class=\"data row4 col0\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row4_col1\" class=\"data row4 col1\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row4_col2\" class=\"data row4 col2\" >0.980000</td>\n",
              "      <td id=\"T_c361c_row4_col3\" class=\"data row4 col3\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row4_col4\" class=\"data row4 col4\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row5\" class=\"row_heading level0 row5\" >Doc5</th>\n",
              "      <td id=\"T_c361c_row5_col0\" class=\"data row5 col0\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row5_col1\" class=\"data row5 col1\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row5_col2\" class=\"data row5 col2\" >0.120000</td>\n",
              "      <td id=\"T_c361c_row5_col3\" class=\"data row5 col3\" >0.870000</td>\n",
              "      <td id=\"T_c361c_row5_col4\" class=\"data row5 col4\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row6\" class=\"row_heading level0 row6\" >Doc6</th>\n",
              "      <td id=\"T_c361c_row6_col0\" class=\"data row6 col0\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row6_col1\" class=\"data row6 col1\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row6_col2\" class=\"data row6 col2\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row6_col3\" class=\"data row6 col3\" >0.970000</td>\n",
              "      <td id=\"T_c361c_row6_col4\" class=\"data row6 col4\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row7\" class=\"row_heading level0 row7\" >Doc7</th>\n",
              "      <td id=\"T_c361c_row7_col0\" class=\"data row7 col0\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row7_col1\" class=\"data row7 col1\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row7_col2\" class=\"data row7 col2\" >0.980000</td>\n",
              "      <td id=\"T_c361c_row7_col3\" class=\"data row7 col3\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row7_col4\" class=\"data row7 col4\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row8\" class=\"row_heading level0 row8\" >Doc8</th>\n",
              "      <td id=\"T_c361c_row8_col0\" class=\"data row8 col0\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row8_col1\" class=\"data row8 col1\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row8_col2\" class=\"data row8 col2\" >0.310000</td>\n",
              "      <td id=\"T_c361c_row8_col3\" class=\"data row8 col3\" >0.680000</td>\n",
              "      <td id=\"T_c361c_row8_col4\" class=\"data row8 col4\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row9\" class=\"row_heading level0 row9\" >Doc9</th>\n",
              "      <td id=\"T_c361c_row9_col0\" class=\"data row9 col0\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row9_col1\" class=\"data row9 col1\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row9_col2\" class=\"data row9 col2\" >0.980000</td>\n",
              "      <td id=\"T_c361c_row9_col3\" class=\"data row9 col3\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row9_col4\" class=\"data row9 col4\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row10\" class=\"row_heading level0 row10\" >Doc10</th>\n",
              "      <td id=\"T_c361c_row10_col0\" class=\"data row10 col0\" >0.120000</td>\n",
              "      <td id=\"T_c361c_row10_col1\" class=\"data row10 col1\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row10_col2\" class=\"data row10 col2\" >0.120000</td>\n",
              "      <td id=\"T_c361c_row10_col3\" class=\"data row10 col3\" >0.760000</td>\n",
              "      <td id=\"T_c361c_row10_col4\" class=\"data row10 col4\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row11\" class=\"row_heading level0 row11\" >Doc11</th>\n",
              "      <td id=\"T_c361c_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
              "      <td id=\"T_c361c_row11_col1\" class=\"data row11 col1\" >0.000000</td>\n",
              "      <td id=\"T_c361c_row11_col2\" class=\"data row11 col2\" >0.140000</td>\n",
              "      <td id=\"T_c361c_row11_col3\" class=\"data row11 col3\" >0.860000</td>\n",
              "      <td id=\"T_c361c_row11_col4\" class=\"data row11 col4\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row12\" class=\"row_heading level0 row12\" >Doc12</th>\n",
              "      <td id=\"T_c361c_row12_col0\" class=\"data row12 col0\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row12_col1\" class=\"data row12 col1\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row12_col2\" class=\"data row12 col2\" >0.010000</td>\n",
              "      <td id=\"T_c361c_row12_col3\" class=\"data row12 col3\" >0.980000</td>\n",
              "      <td id=\"T_c361c_row12_col4\" class=\"data row12 col4\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row13\" class=\"row_heading level0 row13\" >Doc13</th>\n",
              "      <td id=\"T_c361c_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
              "      <td id=\"T_c361c_row13_col1\" class=\"data row13 col1\" >0.210000</td>\n",
              "      <td id=\"T_c361c_row13_col2\" class=\"data row13 col2\" >0.240000</td>\n",
              "      <td id=\"T_c361c_row13_col3\" class=\"data row13 col3\" >0.540000</td>\n",
              "      <td id=\"T_c361c_row13_col4\" class=\"data row13 col4\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c361c_level0_row14\" class=\"row_heading level0 row14\" >Doc14</th>\n",
              "      <td id=\"T_c361c_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
              "      <td id=\"T_c361c_row14_col1\" class=\"data row14 col1\" >0.990000</td>\n",
              "      <td id=\"T_c361c_row14_col2\" class=\"data row14 col2\" >0.000000</td>\n",
              "      <td id=\"T_c361c_row14_col3\" class=\"data row14 col3\" >0.000000</td>\n",
              "      <td id=\"T_c361c_row14_col4\" class=\"data row14 col4\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fc7999befb0>"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#dominant topic in each document -> Assing a topic to each document\n",
        "# Create Document - Topic Matrix\n",
        "lda_output = best_lda_model.transform(data_vectorized)\n",
        "# column names\n",
        "topicnames = [\"Topic\" + str(i) for i in range(best_lda_model.n_components)]\n",
        "print(\"len topicnames\",len(topicnames))\n",
        "# index names\n",
        "docnames = [\"Doc\" + str(i) for i in range(len(data))]\n",
        "print(\"len docsnames\",len(docnames))\n",
        "# Make the pandas dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
        "\n",
        "# Get dominant topic for each document\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "df_document_topic['dominant_topic'] = dominant_topic\n",
        "\n",
        "# Styling\n",
        "def color_green(val):\n",
        "    color = 'green' if val > .1 else 'black'\n",
        "    return 'color: {col}'.format(col=color)\n",
        "\n",
        "def make_bold(val):\n",
        "    weight = 700 if val > .1 else 400\n",
        "    return 'font-weight: {weight}'.format(weight=weight)\n",
        "\n",
        "# Apply Style\n",
        "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
        "df_document_topics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "iZ860FW9Dev5",
        "outputId": "7d4271b9-4c15-48c8-beb8-fa25739b1dd0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nivalderramas/dev/horus/lda/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ability</th>\n",
              "      <th>abstract</th>\n",
              "      <th>academic</th>\n",
              "      <th>access</th>\n",
              "      <th>accomplish</th>\n",
              "      <th>accord</th>\n",
              "      <th>account</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>accurate</th>\n",
              "      <th>achieve</th>\n",
              "      <th>...</th>\n",
              "      <th>wide</th>\n",
              "      <th>widely</th>\n",
              "      <th>wireless</th>\n",
              "      <th>word</th>\n",
              "      <th>workshop</th>\n",
              "      <th>world</th>\n",
              "      <th>write</th>\n",
              "      <th>year</th>\n",
              "      <th>yield</th>\n",
              "      <th>zone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Topic0</th>\n",
              "      <td>8.527759</td>\n",
              "      <td>4.880219</td>\n",
              "      <td>3.994038</td>\n",
              "      <td>5.110671</td>\n",
              "      <td>7.002187</td>\n",
              "      <td>30.430120</td>\n",
              "      <td>6.783840</td>\n",
              "      <td>35.970601</td>\n",
              "      <td>0.285995</td>\n",
              "      <td>25.663870</td>\n",
              "      <td>...</td>\n",
              "      <td>0.275104</td>\n",
              "      <td>1.945263</td>\n",
              "      <td>0.257411</td>\n",
              "      <td>44.664639</td>\n",
              "      <td>0.266538</td>\n",
              "      <td>0.259824</td>\n",
              "      <td>0.257680</td>\n",
              "      <td>0.257576</td>\n",
              "      <td>4.859459</td>\n",
              "      <td>0.250050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic1</th>\n",
              "      <td>2.771791</td>\n",
              "      <td>17.388044</td>\n",
              "      <td>0.250072</td>\n",
              "      <td>0.250424</td>\n",
              "      <td>1.703663</td>\n",
              "      <td>11.704027</td>\n",
              "      <td>3.255634</td>\n",
              "      <td>8.085018</td>\n",
              "      <td>0.251788</td>\n",
              "      <td>15.159764</td>\n",
              "      <td>...</td>\n",
              "      <td>6.441608</td>\n",
              "      <td>6.289473</td>\n",
              "      <td>0.250105</td>\n",
              "      <td>0.250301</td>\n",
              "      <td>0.252257</td>\n",
              "      <td>10.819451</td>\n",
              "      <td>0.250016</td>\n",
              "      <td>12.683201</td>\n",
              "      <td>24.806101</td>\n",
              "      <td>8.774293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic2</th>\n",
              "      <td>12.997067</td>\n",
              "      <td>5.103680</td>\n",
              "      <td>0.256092</td>\n",
              "      <td>19.671774</td>\n",
              "      <td>4.041785</td>\n",
              "      <td>5.938177</td>\n",
              "      <td>20.953187</td>\n",
              "      <td>11.348755</td>\n",
              "      <td>3.646248</td>\n",
              "      <td>17.785610</td>\n",
              "      <td>...</td>\n",
              "      <td>7.157460</td>\n",
              "      <td>13.288248</td>\n",
              "      <td>15.241311</td>\n",
              "      <td>0.253980</td>\n",
              "      <td>0.251464</td>\n",
              "      <td>18.005934</td>\n",
              "      <td>2.227521</td>\n",
              "      <td>5.954795</td>\n",
              "      <td>5.071881</td>\n",
              "      <td>0.251877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic3</th>\n",
              "      <td>6.703384</td>\n",
              "      <td>13.628057</td>\n",
              "      <td>34.499798</td>\n",
              "      <td>15.967131</td>\n",
              "      <td>0.252366</td>\n",
              "      <td>27.927676</td>\n",
              "      <td>21.007339</td>\n",
              "      <td>4.595626</td>\n",
              "      <td>11.815969</td>\n",
              "      <td>31.390756</td>\n",
              "      <td>...</td>\n",
              "      <td>8.125828</td>\n",
              "      <td>5.477015</td>\n",
              "      <td>0.251173</td>\n",
              "      <td>2.831080</td>\n",
              "      <td>14.229741</td>\n",
              "      <td>24.914791</td>\n",
              "      <td>12.264782</td>\n",
              "      <td>37.104427</td>\n",
              "      <td>0.262559</td>\n",
              "      <td>8.723780</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 982 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          ability   abstract   academic     access  accomplish     accord  \\\n",
              "Topic0   8.527759   4.880219   3.994038   5.110671    7.002187  30.430120   \n",
              "Topic1   2.771791  17.388044   0.250072   0.250424    1.703663  11.704027   \n",
              "Topic2  12.997067   5.103680   0.256092  19.671774    4.041785   5.938177   \n",
              "Topic3   6.703384  13.628057  34.499798  15.967131    0.252366  27.927676   \n",
              "\n",
              "          account   accuracy   accurate    achieve  ...      wide     widely  \\\n",
              "Topic0   6.783840  35.970601   0.285995  25.663870  ...  0.275104   1.945263   \n",
              "Topic1   3.255634   8.085018   0.251788  15.159764  ...  6.441608   6.289473   \n",
              "Topic2  20.953187  11.348755   3.646248  17.785610  ...  7.157460  13.288248   \n",
              "Topic3  21.007339   4.595626  11.815969  31.390756  ...  8.125828   5.477015   \n",
              "\n",
              "         wireless       word   workshop      world      write       year  \\\n",
              "Topic0   0.257411  44.664639   0.266538   0.259824   0.257680   0.257576   \n",
              "Topic1   0.250105   0.250301   0.252257  10.819451   0.250016  12.683201   \n",
              "Topic2  15.241311   0.253980   0.251464  18.005934   2.227521   5.954795   \n",
              "Topic3   0.251173   2.831080  14.229741  24.914791  12.264782  37.104427   \n",
              "\n",
              "            yield      zone  \n",
              "Topic0   4.859459  0.250050  \n",
              "Topic1  24.806101  8.774293  \n",
              "Topic2   5.071881  0.251877  \n",
              "Topic3   0.262559  8.723780  \n",
              "\n",
              "[4 rows x 982 columns]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#TOPICS KEYWORDS (PESO DE CADA PALABRA EN CADA TOPIC)\n",
        "# Topic-Keyword Matrix\n",
        "df_topic_keywords = pd.DataFrame(best_lda_model.components_)\n",
        "\n",
        "# Assign Column and Index\n",
        "df_topic_keywords.columns = vectorizer.get_feature_names()\n",
        "df_topic_keywords.index = topicnames\n",
        "\n",
        "# View\n",
        "df_topic_keywords.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prob_scores [[0.63078843 0.05036647 0.0654006  0.2534445 ]]\n",
            "['image', 'algorithm', 'base', 'cluster', 'result', 'datum', 'description', 'paper', 'problem', 'feature', 'representation', 'learning', 'learn', 'neural', 'strategy', 'visual', 'classification', 'information', 'genetic', 'evolutionary']\n"
          ]
        }
      ],
      "source": [
        "# PREDICT TOPIC FOR NEW TEXT\n",
        "# Define function to predict topic for a given text document.\n",
        "\n",
        "def predict_topic(text, nlp=nlp):\n",
        "\n",
        "    # Step 1: Clean with simple_preprocess\n",
        "    tokenized_words = list(tokenize_words(text))\n",
        "\n",
        "    # Step 2: Lemmatize\n",
        "    lemmatized_words = lemmatization(tokenized_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "    # Step 3: Vectorize transform\n",
        "    vectorized_words = vectorizer.transform(lemmatized_words)\n",
        "\n",
        "    # Step 4: LDA Transform\n",
        "    topic_probability_scores = best_lda_model.transform(vectorized_words)\n",
        "    topic = df_n_relevant_topic_keywords.iloc[np.argmax(topic_probability_scores), :].values.tolist()\n",
        "    return topic, topic_probability_scores\n",
        "\n",
        "# Predict the topic\n",
        "mytext = [\"algorithm to predict cancer on colombian computers\"]\n",
        "topic, prob_scores = predict_topic(text = mytext)\n",
        "print(\"prob_scores\",prob_scores)\n",
        "print(topic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Get similar documents for a given text\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "\n",
        "def similar_documents(text, doc_topic_probs, documents = data, nlp=nlp, top_n=5, verbose=False):\n",
        "    topic, x  = predict_topic(text)\n",
        "    dists = euclidean_distances(x.reshape(1, -1), doc_topic_probs)[0]\n",
        "    doc_ids = np.argsort(dists)[:top_n]\n",
        "    if verbose:        \n",
        "        print(\"Topic KeyWords: \", topic)\n",
        "        print(\"Topic Prob Scores of text: \", np.round(x, 1))\n",
        "        print(\"Most Similar Doc's Probs:  \", np.round(doc_topic_probs[doc_ids], 1))\n",
        "    return doc_ids, np.take(documents, doc_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get similar documents\n",
        "def get_n_similar_publications(text, N = 1):\n",
        "  doc_ids, docs = similar_documents(text=text, doc_topic_probs=lda_output, documents = data, top_n=N, verbose=True)\n",
        "  for i in range(len(docs)):\n",
        "    print(\"*\"*10)\n",
        "    print(i,docs[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic KeyWords:  ['network', 'base', 'paper', 'design', 'description', 'environment', 'service', 'software', 'agent', 'result', 'information', 'allow', 'architecture', 'tool', 'programming', 'implementation', 'communication', 'problem', 'control', 'user']\n",
            "Topic Prob Scores of text:  [[0.1 0.1 0.7 0.1]]\n",
            "Most Similar Doc's Probs:   [[0.1 0.1 0.7 0.1]\n",
            " [0.1 0.  0.8 0.1]\n",
            " [0.  0.1 0.8 0.1]\n",
            " [0.1 0.1 0.8 0. ]\n",
            " [0.1 0.2 0.8 0. ]\n",
            " [0.1 0.  0.8 0.1]\n",
            " [0.1 0.  0.8 0.2]\n",
            " [0.  0.2 0.7 0.1]\n",
            " [0.  0.  0.8 0.1]\n",
            " [0.  0.  0.8 0.1]\n",
            " [0.1 0.  0.9 0. ]\n",
            " [0.2 0.  0.8 0. ]\n",
            " [0.2 0.  0.8 0. ]\n",
            " [0.2 0.  0.8 0. ]\n",
            " [0.  0.  0.8 0.2]]\n",
            "**********\n",
            "0 dc:title:eng:Certification and International Mobility of Engineering Professionals in Colombia: A Literature Review \n",
            "**********\n",
            "1 dc:description:eng:© 2018 IEEE.South American countries are not in the top of E-Government development, As a proof of this, in the EGovernment Develop Index survey given by the United Nations, no country of the region have been in the top 20 of the index. Additionally, from the first survey to the last in 2016, no one have been cataloged with a very high score of development. Even worse according to the same survey all countries in South America have regressed relative to the rest of the world. In this paper is analyzed the South America E-Government performance based in the United Nation surveys taking into account the each subindexes that composed the surveys and comparing the region with the E-Government top countries in 2016. Finally, it is suggested a set of strategies that could help to improve the index values.\n",
            "**********\n",
            "2 dc:description:eng:One of the most important problems in the evolution of legacy systems is the loss of knowledge about them. In this paper, we present an approach for extracting structural business rules from legacy databases. We used the technique to recover business rules from SIFI (SIstema Fiduciario Integra do), an existing legacy system, implemented mostly in PL/SQL and Oracle Forms. Four employees of the company that know the system and its domain evaluated the extracted rules in order to assess the precision of the extraction technique. The results show that 29% of recovered rules are correct structural business rules, 36% correspond to implementation rules, and 35% are incomplete or incorrect rules. The recovery technique proves to be practical, while there is room for improvement, and it will be used as basis for the recovery of additional types of business rules. © 2012 IEEE.\n",
            "**********\n",
            "3 dc:description:eng:© 2016 ACM.Personality traits inuence most, if not all, of the human activities, from those as natural as the way people walk, talk, dress and write to those most complex as the way they interact with others. Most importantly, personality inuences the way people make decisions including, in the case of developers, the criteria they consider when selecting a software project they want to participate. Most of the works that study the inuence of social, technical and human factors in software development projects have been focused on the impact of communications in software quality. For instance, on identifying predictors to detect files that may contain bugs before releasing an enhanced version of a software product. Only a few of these works focus on the analysis of personality traits of developers with commit permissions (committers) in Free/Libre and Open-Source Software projects and their relationship with the software artifacts they interact with. This paper presents an approach, based on the automatic recognition of personality traits from e-mails sent by committers in FLOSS projects, to uncover relationships between the social and technical aspects that occur during the software development process. Our experimental results suggest the existence of some relationships among personality traits projected by the committers through their e-mails and the social (communication) and technical activities they undertake. This work is a preliminary study aimed at supporting the setting up of efficient work teams in software development projects based on an appropriate mix of stakeholders taking into account their personality traits.\n",
            "**********\n",
            "4 _id:8287\n",
            "**********\n",
            "5 dc:description:eng:© 2019 University of Minho. All rights reserved.This work summarizes three different strategies used to motivate the curricular transformation of engineering curricula in Colombia, for promoting the design and application of student-centered approaches and particularly, Project Based Learning. The proposed strategies include i) a teacher training program in PBL, ii) the definition of strategies for PBL spreading and iii) strengthening of Engineering Education Community. The first strategy considers a training course for engineering teachers, which deals the PBL philosophy and how to apply it in engineering subjects. The second one focuses on creating learning spaces such as workshops, meetings or seminars to promote the use of PBL in Engineering and the third one, focuses on the creation common graduate programs and the Colombian Network of PBL in Engineering. The results presented herein correspond to the second strategy, for which the researchers designed and developed a PBL Workshop that used as the trigger of the learning process the 'marshmallow challenge.' The workshop is carried out as a part of the International Meeting of Engineering Education (EIEI ACOFI 2018), in which teachers from different universities participate. The workshop emphasizes the 'exemplarity' principle, offering a complete scenario to live a PBL experience.\n",
            "**********\n",
            "6 _id:70298\n",
            "**********\n",
            "7 dc:title:eng:Source apportionment of PM10 in Bogotá. Integrated study in three different points\n",
            "**********\n",
            "8 _id:2726\n",
            "**********\n",
            "9 _id:20751\n",
            "**********\n",
            "10 dc:title:eng:On automatically generating commit messages via summarization of source code changes\n",
            "**********\n",
            "11 dc:title:eng:Performance analysis of communication protocols for Internet of things platforms\n",
            "**********\n",
            "12 dc:title:eng:EHeart-BP, Prototype of the Internet of Things to Monitor Blood Pressure\n",
            "**********\n",
            "13 dc:description:eng:© 2001 IEEE.A visualization scheme as a tool to find the solution of any 3D-linear programming problem is introduced. The presented approach is highly suitable to draw and visualize interactively the feasible region of a given 3D-linear programming problem. It can be used for a better understanding of the solution process when different methods devoted to solve the underlying problem are applied, e.g., the simplex method. The proposed technique comprises sensitive analysis during the solution process and interactive visualization of the feasible region. The analysis leading to the introduced schema also shows that the design of an appropriate and simple vertex representation is crucial to manage any order of degeneracy. To deal with this paradigm and to some extent to formalize it, the concept of adjacency invariance is introduced. Several experiments have been conducted to test and assess the performance of the introduced concepts and techniques.\n",
            "**********\n",
            "14 dc:title:eng:Optimal Design of Energy Systems in Isolated Zones Using Sustainability Indicators. A Case Study in the Colombian Amazon\n"
          ]
        }
      ],
      "source": [
        "get_n_similar_publications([\"detection of malicious user in mobile\"], N = 15)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "830c8696d55471405506006ee84ce951f1fee1ebc23505c2f5c8bcda98bf35ae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
